
# Video Work Flow

The package includes support for automatically capturing canvas frames using
<a href="https://developers.google.com/web/tools/puppeteer">Puppeteer</a>
in combination with 
<a href="https://developers.google.com/web/updates/2017/04/headless-chrome">headless Chrome</a>.
This is only feasible on a platform where headless Chrome can find an use a real GPU for
graphics acceleration.

# Requirements

You will need recent versions of the `node` intepreter with the `npm` package manager and the 
<a href="https://ffmpeg.org/ffmpeg.html">ffmpeg</a> conversion program to run the video
creation workflow. 

I installed `node` and `npm` using 
<a href="https://anaconda.org/conda-forge/nodejs">the conda tool set</a>

```
$ conda install -c conda-forge nodejs 
...
$ node -v
v13.13.0
```

# Installing the tools

- Install the `radiation_viz` Python 3 module as described in its <a href="README.md">README</a>.

- Install the `image_capturer` node components as described in its <a href="image_capturer/README.txt">READMe</a>.

```
$ cd image_capturer
$ npm install
```

The `npm install` will automatically pull in `puppeteer` and headless Chrome.

- Install the <a href="https://jasonwatmore.com/post/2016/06/22/nodejs-setup-simple-http-server-local-web-server">http-server node script globally.</a>

```
npm install -g http-server
```

*Note:* The implementation uses `http-server` rather than `python -m http.server` because
I've noticed that the Python based server sometimes locks up and I haven't yet seen this
with `http-server`.

# The workflow

To create a video do the following

- Generate the visualization web tree from the source data files.
- View the visualization using a server and a browser and choose the camera settings you want for the video,.
- Generate the image frames from the visualization tree (this step must run where headless Chrome recognizes a GPU.)
- Combine the image frames into a video.

Each of thes steps are described in a subsection below.

# Check your GPU!

The image-capture step of the workflow will only complete in reasonable time if it uses a headless
browser that uses a real hardware based GPU.  In the environment for the image capture step
verify that a *real* GPU is available using the `image_capturer/gpu_detect.js` node script:
```
$ node gpu_detect.js
(node:60509) ExperimentalWarning: The fs.promises API is experimental
HeadlessChrome/81.0.4044.0
ANGLE (ATI Technologies Inc., AMD Radeon Pro 560X OpenGL Engine, OpenGL 4.1 core)
```
In the case above the script detected a real hardware GPU `Radeon Pro 560X`.

## Don't use a GPU emulator!!!

```
$ node gpu_detect.js 
HeadlessChrome/81.0.4044.0
Google SwiftShader
```
In the case above the script detected the emulator software `Google SwiftShader`.
**If you see something like this the image capture will not complete in your lifetime --
run away and find a machine where the GPU will be detected by headless Chrome.**


## Generate the visualization web tree from the source data files.

To generate the web visualization tree each of the input source files must be processed by
the `radiation_viz.prepare_viz_data` script.  Since there may be a lot of input files and you
may want to process them in parallel there is a helper script `radiation_viz.build_plan` which
will build a sequence of command lines which each process one input file.   The command
sequence may be directly executed or it submitted to a batch scheduler on a cluster.

### Generating a `plan.sh`

For example the invocation

```
$ python -m radiation_viz.build_plan \
     ~/misc/Yan-Fei_Jiang/ \
      ~/tmp/radiation_test \
     --skip 4 --limit 1 --clean --var_substring rho --out ~/tmp/output > plan.sh
```

Generates a plan for creating a visualization tree from 1 file 

- Matching `*.athdf` 
- Found in the `~/misc/Yan-Fei_Jiang/` directory
- The tree will be built at `~/tmp/radiation_test`
- Only the variable `rho` in the input file will be processed.
- The `--skip 4` flag directs the script to generate data files with low resolution (which makes the interactive visualization more responsive).  
- The `--clean` flag specifies that if the `~/tmp/radiation_test` folder exists it should be deleted and replaced.
- Diagnostic log files will be written to `~/tmp/output`.

Here are the `plan.txt` command lines generated by the command above with some whitespace added for clarity:

```
python -u -m radiation_viz.prepare_viz_data \
    /Users/awatters/misc/Yan-Fei_Jiang/disk.out1.13926.athdf \
    --clean --var_substring rho --truncated --skip 4 --no_config \
    --to_directory /Users/awatters/tmp/radiation_test --force \
        > /Users/awatters/tmp/output/disk.out1.13926.athdf.log 2>&1

python -u -m radiation_viz.prepare_viz_data \
    dummy_argument.athdf --config_only --to_directory /Users/awatters/tmp/radiation_test --force \
    > /Users/awatters/tmp/output/config.json.log 2>&1
```

The first line processes the file `/Users/awatters/misc/Yan-Fei_Jiang/disk.out1.13926.athdf`
extracting the `rho` variable into data files which can be imported into the visualization.

The second and last line generates a `config.json` file for the visualization listing all data files.

### Executing a small `plan.sh`

To create the web tree from the plan we must execute the plan.  For small plans on a laptop
we can simply run the commands in sequence using `source`:

```
$ source plan.sh
```

The commands populate the directory `/Users/awatters/tmp/radiation_test` with the following files:

```
(base) C02XD1KGJGH8:radiation_test awatters$ find .
.
./index.html
./css
./css/styles.css
./css/jquery-ui.css
./css/normalize.css
./js
./js/filesaver.js
./js/three.min.js
./js/three.js
./js/index.js
./js/feedWebGL.js
./js/feedbackSurfaces.js
./js/jquery.min.js
./js/three_sprite_text.js
./js/feedbackMatrix.js
./js/dual_canvas_helper.js
./js/cat_scan2.js
./js/canvas_2d_widget_helper.js
./js/OrbitControls.js
./js/feedbackContours.js
./js/jquery-ui.js
./config.json
./processed_data
./processed_data/disk.out1.13926_rho_skip_4.bin
./processed_data/.gitattributes
./processed_data/disk.out1.13926_rho_skip_4.json
./processed_data/small_data_test.bin
./processed_data/small_data_test.json
./main.js
```

Here `./index.html` is the "index file" for the web based visualization.

### Executing larger plans

The plan given above just processed one file.  The following invocation creates a plan for processing potentially thousands of files

```
$ python -m radiation_viz.build_plan \
    /mnt/home/yjiang/ceph/CVDisk/CVIsoB2/Data_finished \
    /mnt/ceph/users/awatters/viz \
    --clean  --var_substring rho \
    --out /mnt/ceph/users/awatters/logs --limit 3000 > plan.sh
```

The above generates a plan for creating a visualization tree from up to 3000 files

- Matching `*.athdf` 
- Found in the `/mnt/home/yjiang/ceph/CVDisk/CVIsoB2/Data_finished` directory
- The tree will be built at `/mnt/ceph/users/awatters/viz`
- Only the variable `rho` in the input files will be processed.
- The `--clean` flag specifies that if the `/mnt/ceph/users/awatters/viz` folder exists it should be deleted and replaced.
- Diagnostic log files will be written to `/mnt/ceph/users/awatters/logs`.

Since each command line of the plan takes a couple minutes to execute on a single core,
we submit the commands in the plan to a batch scheduler.  At flatiron we use `slurm` and `disBatch` like this:

```
$ module load slurm
$ module load disBatch
$ sbatch -n 5 --ntasks-per-node 5 --wrap "disBatch.py plan.sh"
Submitted batch job 552107
```

## View the visualization using a server and a browser and choose the camera settings you want for the video.

Once the visualization tree is built we can view the first 100 data files in the tree using the web interface.
You may use one of the visualization views to select the iso-surface cutoff value and camera position
for the video image captures.

### First start a web server above the top of the web tree in a console window:

```
$ cd /mnt/ceph/users/awatters/
$ http-server . -p 9432
```

### Then open the page `http://SERVER-NAME-OR-IP:9432/` and navigate to the visualization.

If you are running locally the page will be of the form `http://localhost:9432`.

### Selecting camera settings and cutoff values

The image capture sequence allows the specification of an iso-surface cutoff value and a camera position
using a `camera_settings.json` data file.  In your browser view of the visualization set the camera
position and cutoff value as desired and then download the settings file using the "Download camera settings" button.

Stop the web server in the console using CONTROL-C.

## Generate the image frames from the visualization tree.



## Combine the image frames into a video.

